{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPwwIRHyh03x0GIavEPWIoa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## üöÄ ¬°Ahora Te Toca a Vos!\n","\n","Ahora que ya armaste tu propio generador de descripciones de im√°genes, seguro ten√©s varias ideas.\n","\n","Por eso, te propongo un desaf√≠o: **¬°pensar y explorar otras aplicaciones que pod√©s desarrollar con lo que ya sab√©s!** No ten√©s que hacerlas todas, ¬°pero fijate cu√°l te gusta m√°s para seguir practicando y creando!\n","\n","---\n","### üîç Aplicaciones de An√°lisis Visual\n","\n","Ac√° vas a usar la IA para \"entender\" lo que se ve en las im√°genes y sacar conclusiones.\n","\n","1.  **Detector de Emociones en Rostros**\n","    *   ¬øQuer√©s que tu computadora identifique si una persona est√° feliz, triste o enojada en una foto? ¬°Con esto lo pod√©s hacer!\n","    *   Vas a usar un `pipeline` similar al de la clase, pero con un modelo entrenado espec√≠ficamente para detectar emociones.\n","    *   **Input:** Una `selfie` o una foto donde aparezcan personas.\n","    *   **Output esperado:** Vas a ver un texto como: \"Esta imagen muestra una persona feliz/triste/sorprendida\".\n","    *   **Extra:** Pod√©s traducir las emociones al espa√±ol y, si te anim√°s, ¬°hasta dar alg√∫n consejito b√°sico seg√∫n la emoci√≥n detectada!\n","\n","    ```python\n","    # Este es el modelo que vas a usar, fijate que es de 'image-classification'.\n","    # Pod√©s reemplazarlo por otro si investig√°s y encontr√°s uno que te guste m√°s.\n","    # Acordate de importar el 'pipeline' de 'transformers'.\n","    # from transformers import pipeline\n","    emotion_pipeline = pipeline(\"image-classification\",\n","                               model=\"j-hartmann/emotion-english-distilroberta-base\")\n","\n","    # Para probarlo, necesit√°s una imagen. Si quer√©s, pod√©s abrir una as√≠:\n","    # from PIL import Image\n","    # img_ejemplo = Image.open(\"ruta/a/tu/imagen_con_rostro.jpg\")\n","    # print(emotion_pipeline(img_ejemplo))\n","    ```\n","\n","2.  **Clasificador de Comidas + Contador de Calor√≠as**\n","    *   ¬°Imaginate sacar una foto de tu almuerzo y que la compu te diga qu√© comida es y cu√°ntas calor√≠as tiene!\n","    *   Ac√° pod√©s usar un clasificador de im√°genes de comidas y, el plus, ser√≠a conectarlo con una API de nutrici√≥n para obtener los datos de calor√≠as.\n","    *   **Input:** Una foto de un plato de comida.\n","    *   **Output esperado:** Te deber√≠a decir algo como: \"Pizza - Aproximadamente 350 calor√≠as por porci√≥n\".\n","    *   **Gradio:** Ideal para armar una interfaz en Gradio donde sub√≠s la foto de lo que vas a comer.\n","\n","    ```python\n","    food_classifier = pipeline(\"image-classification\",\n","                              model=\"nateraw/food\")\n","    # Para el conteo de calor√≠as, vas a necesitar investigar alguna API de nutrici√≥n (como USDA FoodData Central)\n","    # y combinar los resultados del clasificador con esa informaci√≥n.\n","    ```\n","\n","3.  **Identificador de Plantas/Animales**\n","    *   ¬øTe gusta la jardiner√≠a o te cruz√°s con un bicho y no sab√©s qu√© es?\n","    *   Pod√©s usar modelos ya entrenados para clasificar plantas o animales (como el `google/vit-base-patch16-224` si lo reentren√°s para esa tarea espec√≠fica o busc√°s una versi√≥n ya `fine-tuneada` para esto).\n","    *   **Aplicaci√≥n:** Ser√≠a un \"¬øQu√© planta es esta?\" perfecto para cualquier amante de la jardineria.\n","    *   **Plus:** Agregale info sobre los cuidados b√°sicos de la planta o datos curiosos del animal que identific√≥.\n","\n","---\n","### üé® Aplicaciones Creativas\n","\n","¬°Ac√° pod√©s soltar tu imaginaci√≥n y usar la IA para generar cosas nuevas o asistirte en tareas creativas!\n","\n","4.  **Generador de Memes Autom√°tico**\n","    *   ¬°Ac√° pod√©s soltar tu creatividad! Combin√° tu `Image Captioning` de la clase con algunas plantillas de memes.\n","    *   La idea es que el sistema genere una descripci√≥n y, bas√°ndose en ella, elija la plantilla de meme m√°s adecuada y le agregue el texto.\n","    *   **Recordate:** Vas a necesitar la funci√≥n `generar_descripcion` de la clase anterior.\n","\n","    ```python\n","    # La idea es que tu funci√≥n 'generar_meme' use 'generar_descripcion'\n","    # para obtener un texto, y luego use librer√≠as de procesamiento de imagen\n","    # como PIL (Pillow) para agregar ese texto a una plantilla de meme.\n","    # def generar_meme(imagen):\n","    #     descripcion_dict = generar_descripcion(imagen) # Te va a dar el diccionario con descripciones.\n","    #     descripcion_es = descripcion_dict['Descripci√≥n (Espa√±ol)']\n","    #     # Ac√° ten√©s que agregar la l√≥gica para elegir un template de meme (quiz√°s predefinidos)\n","    #     # y agregar el texto de la 'descripcion_es' a la imagen.\n","    #     # Esto va a requerir un poco de procesamiento de im√°genes con Pillow o OpenCV.\n","    #     return agregar_texto_a_meme_template(imagen, descripcion_es) # Ejemplo de funci√≥n auxiliar\n","    ```\n","\n","5.  **Asistente de Outfit**\n","    *   ¬øNo sab√©s qu√© ponerte? Un sistema de IA te puede dar una mano.\n","    *   **Input:** Una foto de alguna prenda de ropa que tengas.\n","    *   **Output esperado:** Te podr√≠a sugerir: \"Camisa azul formal - Combinar√≠a bien con pantal√≥n negro y zapatos marrones\".\n","    *   Vas a necesitar modelos de clasificaci√≥n de ropa (`fashion classification`) y luego armar reglas de combinaci√≥n (¬°quiz√°s con un poco de l√≥gica `if/else` y tu creatividad!).\n","\n","---\n","### ‚ôø Aplicaciones de Accesibilidad\n","\n","Estos proyectos tienen un impacto social muy grande ayudando a personas con diferentes capacidades.\n","\n","6.  **Lector de Documentos para Personas con Discapacidad Visual**\n","    *   Un proyecto con un impacto social enorme. Tu computadora podr√≠a \"leer\" documentos y \"hablar\" el texto.\n","    *   Vas a combinar `OCR` (Reconocimiento √ìptico de Caracteres, para extraer texto de im√°genes) con `Text-to-Speech` (para convertir el texto en voz).\n","    *   **Acordate:** Necesit√°s instalar librer√≠as como `pyttsx3` para el `Text-to-Speech`.\n","\n","    ```python\n","    # Este pipeline te permite extraer texto de una imagen.\n","    ocr_pipeline = pipeline(\"image-to-text\", model=\"microsoft/trocr-base-printed\")\n","    # Para convertir el texto en voz, vas a necesitar una librer√≠a como 'pyttsx3'\n","    # o alguna API de Text-to-Speech que te guste.\n","    # import pyttsx3\n","    # engine = pyttsx3.init()\n","    # engine.say(\"Hola, esta es una prueba de voz para la gu√≠a.\")\n","    # engine.runAndWait() # Esto hace que la voz se reproduzca.\n","    ```\n","\n","7.  **Descriptor de Escenas para Redes Sociales**\n","    *   ¬°Pod√©s mejorar tu sistema de `Image Captioning` de hoy para que sea a√∫n m√°s √∫til!\n","    *   La idea es generar descripciones bien detalladas de im√°genes para que personas con discapacidad visual puedan entender qu√© comparten sus amigos en redes sociales.\n","    *   **Plus:** Podr√≠as incluso generar `hashtags` autom√°ticamente relacionados con la descripci√≥n, ¬°para que tu amigo con discapacidad visual tambi√©n pueda compartirlas f√°cilmente!\n","\n","---\n","### üè† Aplicaciones Dom√©sticas\n","\n","¬°La IA tambi√©n te puede ayudar a tener tu casa m√°s organizada y tu vida m√°s f√°cil!\n","\n","8.  **Organizador de Fotos Inteligente**\n","    *   ¬øTen√©s miles de fotos y no las encontr√°s? Podes crear un sistema de IA que las organice por vos.\n","    *   La idea es usar tu `Image Captioning` para generar descripciones y, bas√°ndote en palabras clave de esas descripciones, crear carpetas y organizar tus fotos autom√°ticamente (por ejemplo, \"Mascotas\", \"Viajes\", \"Familia\").\n","    *   **Recordate:** Vas a usar tu funci√≥n `generar_descripcion`.\n","\n","    ```python\n","    # Tu funci√≥n 'clasificar_foto' usar√≠a tu 'generar_descripcion'.\n","    # def clasificar_foto(imagen_path):\n","    #     img = Image.open(imagen_path)\n","    #     descripcion_dict = generar_descripcion(img)\n","    #     descripcion_es = descripcion_dict['Descripci√≥n (Espa√±ol)']\n","    #     # Ac√° ten√©s que implementar la l√≥gica 'decidir_carpeta'.\n","    #     # Por ejemplo: si 'perro' o 'gato' est√°n en la descripci√≥n_es, mover a la carpeta 'Mascotas'.\n","    #     # Vas a necesitar usar funciones de Python para manejar archivos y carpetas (os.makedirs, shutil.move).\n","    #     carpeta_destino = decidir_carpeta(descripcion_es)\n","    #     # Mover el archivo a la carpeta destino\n","    #     # shutil.move(imagen_path, os.path.join(\"tu_ruta_base\", carpeta_destino))\n","    ```\n","\n","9.  **Control de Inventario Casero**\n","    *   Olvidate de que se te venzan las cosas en la heladera. Una app para tu celular que te ayude a controlar lo que ten√©s.\n","    *   **Input:** Una foto de tu heladera o despensa.\n","    *   **Output esperado:** Una lista de los productos que ten√©s, y, si te anim√°s, una fecha estimada de vencimiento (¬°esto √∫ltimo es un desaf√≠o m√°s grande!).\n","    *   **Gradio:** Ideal para armar una interfaz de Gradio para la gesti√≥n dom√©stica de alimentos.\n","\n","---\n","### üìö Aplicaciones Educativas\n","\n","La IA es una herramienta incre√≠ble para el aprendizaje y la ense√±anza.\n","\n","10. **Tutor Visual de Matem√°ticas**\n","    *   ¬°Ayud√° a tus compa√±eros con matem√°ticas! Una IA que \"lea\" una ecuaci√≥n de una foto y la resuelva.\n","    *   Vas a necesitar `OCR` espec√≠fico para texto escrito a mano (para que lea tus apuntes o ejercicios) y luego integrar eso con alguna librer√≠a de Python que resuelva ecuaciones (como `SymPy`).\n","\n","    ```python\n","    # Este modelo de Hugging Face es para texto manuscrito.\n","    math_pipeline = pipeline(\"image-to-text\", model=\"microsoft/trocr-base-handwritten\")\n","    # Despu√©s de extraer la ecuaci√≥n, vas a necesitar integrar con una librer√≠a como SymPy\n","    # import sympy\n","    # x = sympy.Symbol('x')\n","    # ecuacion = \"x**2 - 4\" # Esto vendr√≠a del OCR\n","    # print(sympy.solve(ecuacion, x)) # Ejemplo de c√≥mo resolver\n","    ```\n","\n","11. **Identificador de Obras de Arte**\n","    *   ¬°Visit√° un museo con tu celular y que la IA te cuente todo sobre una obra!\n","    *   La idea es clasificar pinturas o esculturas famosas.\n","    *   **Output esperado:** Te dir√≠a algo como: \"Esta es 'La Noche Estrellada' de Van Gogh (1889)\".\n","    *   **Plus:** Agregale datos hist√≥ricos, curiosidades del artista o del movimiento art√≠stico.\n","\n","---\n","### üõí Aplicaciones Comerciales Simples\n","\n","¬°Estas ideas te muestran c√≥mo la IA puede ser √∫til en negocios o para ayudarte con tus compras!\n","\n","12. **Comparador de Precios Visual**\n","    *   ¬°Olvidate de buscar precios en la web! Sacale una foto a una etiqueta y que la IA te diga d√≥nde est√° m√°s barato.\n","    *   Vas a usar `OCR` para leer los precios y el nombre del producto de una etiqueta, y luego una b√∫squeda web para encontrar los mejores precios.\n","\n","    ```python\n","    # Ac√° tendr√≠as que combinar OCR (para el precio y el nombre del producto)\n","    # con una funci√≥n de b√∫squeda web (usando librer√≠as como 'requests' para obtener el HTML de p√°ginas\n","    # de supermercados y 'BeautifulSoup' para extraer la informaci√≥n).\n","    # def comparar_precio(imagen_producto_path):\n","    #     img = Image.open(imagen_producto_path)\n","    #     producto_y_precio = identificar_producto_y_precio(img) # Necesit√°s una funci√≥n que haga OCR y extraiga.\n","    #     if producto_y_precio:\n","    #         return buscar_mejores_precios(producto_y_precio['producto']) # Funci√≥n que hace la b√∫squeda web.\n","    ```\n","\n","13. **Verificador de Calidad de Productos**\n","    *   ¬øEsa fruta est√° buena? ¬øEste tomate est√° maduro? ¬°Tu IA te ayuda a elegir en la verduler√≠a!\n","    *   **Input:** Una foto de una fruta, verdura o alg√∫n otro producto.\n","    *   **Output esperado:** Te dir√≠a: \"Manzana madura - Buena para consumir\" o \"Tomate verde - Esperar unos d√≠as\".\n","    *   Esto requerir√≠a entrenar un modelo de clasificaci√≥n espec√≠fico para la frescura de productos (o encontrar uno ya pre-entrenado).\n","\n","---\n","### üéØ La M√°s Simple para Empezar: ¬°Detector de Emociones!\n","\n","De todas estas ideas, para arrancar y seguir practicando con lo que **aprendiste** hoy, te recontra recomiendo el **Detector de Emociones en Rostros**.\n","\n","**¬øPor qu√© es la mejor opci√≥n para empezar?**\n","\n","*   **Similar a lo que ya hiciste:** Usa la misma estructura de `pipeline` que ya manejaste en la clase. ¬°Vas a estar en tu salsa!\n","*   **Modelos listos:** Los modelos necesarios ya est√°n disponibles en Hugging Face, listos para usar. ¬°No ten√©s que entrenar nada nuevo!\n","*   **Impacto visual y f√°cil de entender:** Es s√∫per copado ver c√≥mo detecta las emociones y es f√°cil de explicar a cualquiera.\n","*   **F√°cil de implementar:** Vas a ver que con pocas l√≠neas de c√≥digo, ten√©s algo funcionando."],"metadata":{"id":"n0J5A2rPb9Au"}},{"cell_type":"markdown","source":["**Acordate que ser√≠a algo as√≠ de simple:**"],"metadata":{"id":"jakIWdTbeJ0y"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"K8QrnhgEb8Nd"},"outputs":[],"source":["# Primero, asegurate de tener importado el 'pipeline' de 'transformers'.\n","# from transformers import pipeline\n","# Y tambi√©n tu traductor, si quer√©s la emoci√≥n en espa√±ol (¬°que te re sugiero!).\n","# Necesit√°s haber ejecutado la celda donde configuraste el traductor antes.\n","# traductor = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n","\n","# Este es el modelo de clasificaci√≥n de im√°genes para emociones.\n","emotion_classifier = pipeline(\"image-classification\",\n","                             model=\"j-hartmann/emotion-english-distilroberta-base\")\n","\n","def detectar_emocion(imagen):\n","    \"\"\"\n","    Detecta la emoci√≥n en un rostro dentro de una imagen y la traduce al espa√±ol.\n","    \"\"\"\n","    # La funci√≥n 'emotion_classifier' te devuelve una lista de diccionarios con los resultados.\n","    # Nos interesa el primer elemento, que es el resultado con mayor confianza.\n","    resultado = emotion_classifier(imagen)\n","    emocion_en = resultado[0]['label'] # Ac√° est√° la emoci√≥n en ingl√©s (e.g., 'happy', 'sad', 'angry')\n","\n","    # Ahora, ¬°a traducir!\n","    # Le pasamos una frase completa al traductor para que tenga m√°s contexto y la traducci√≥n sea mejor.\n","    emocion_es = traductor(f\"The person looks {emocion_en}\")[0]['translation_text']\n","\n","    # Y devolvemos todo en un diccionario, incluyendo la confianza del modelo.\n","    # El f-string con ':.2%' formatea el score como un porcentaje con dos decimales.\n","    return {\n","        \"Emoci√≥n detectada (English)\": emocion_en,\n","        \"Emoci√≥n en espa√±ol\": emocion_es,\n","        \"Confianza del modelo\": f\"{resultado[0]['score']:.2%}\"\n","    }\n","\n","# Para probarlo, necesitar√≠as una imagen con un rostro.\n","# Pod√©s cargarla as√≠ (acordate de tener Pillow instalado: !pip install Pillow):\n","# from PIL import Image\n","# # Asegurate de poner la ruta correcta a una imagen tuya que tenga un rostro\n","# img_para_probar = Image.open(\"ruta/a/tu/foto_con_rostro.jpg\")\n","\n","# # Ahora, ¬°a probar la funci√≥n!\n","# resultados_emocion = detectar_emocion(img_para_probar)\n","# print(resultados_emocion)\n","\n","# Y si quer√©s, ¬°pod√©s armar una interfaz con Gradio para esto tambi√©n!\n","# gr.Interface(fn=detectar_emocion, inputs=gr.Image(type=\"pil\"), outputs=\"json\",\n","#              title=\"Detector de Emociones\",\n","#              description=\"Sub√≠ una foto y mir√° qu√© emoci√≥n detecta el modelo.\").launch(share=True)"]}]}